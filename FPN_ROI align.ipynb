{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a4_helper.VOC2007DetectionTiny object at 0x000001DB1ADC8C48>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wuxin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: [WinError 126] The specified module could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from a4_helper import *\n",
    "from eecs598 import reset_seed\n",
    "import multiprocessing\n",
    "\n",
    "# Set a few constants related to data loading.\n",
    "NUM_CLASSES = 20\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SHAPE = (224*4, 224*4)\n",
    "NUM_WORKERS = multiprocessing.cpu_count()\n",
    "from a4_helper import VOC2007DetectionTiny\n",
    "\n",
    "train_dataset = VOC2007DetectionTiny(\n",
    "    './A4', \"train\", image_size=IMAGE_SHAPE[0],\n",
    "    download=False  # True (for the first time)\n",
    ")\n",
    "val_dataset = VOC2007DetectionTiny('./A4', \"val\", image_size=IMAGE_SHAPE[0])\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dummy input images with shape: (2, 3, 224, 224)\n",
      "Shape of p3 features: torch.Size([2, 64, 28, 28])\n",
      "Shape of p4 features: torch.Size([2, 64, 14, 14])\n",
      "Shape of p5 features: torch.Size([2, 64, 7, 7])\n",
      "Shape of p6 features: torch.Size([2, 64, 4, 4])\n",
      "Shape of p7 features: torch.Size([2, 64, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from common import DetectorBackboneWithFPN\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# sanity check\n",
    "backbone = DetectorBackboneWithFPN(out_channels=64)\n",
    "\n",
    "dummy_images = torch.randn(2, 3, 224, 224)\n",
    "\n",
    "dummy_fpn_feats = backbone(dummy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'stem.0', 'stem.1', 'stem.2', 'trunk_output.block1.block1-0.proj.0', 'trunk_output.block1.block1-0.proj.1', 'trunk_output.block1.block1-0.f.a.0', 'trunk_output.block1.block1-0.f.a.1', 'trunk_output.block1.block1-0.f.a.2', 'trunk_output.block1.block1-0.f.b.0', 'trunk_output.block1.block1-0.f.b.1', 'trunk_output.block1.block1-0.f.b.2', 'trunk_output.block1.block1-0.f.c.0', 'trunk_output.block1.block1-0.f.c.1', 'trunk_output.block1.block1-0.add', 'trunk_output.block1.block1-0.activation', 'trunk_output.block2.block2-0.proj.0', 'trunk_output.block2.block2-0.proj.1', 'trunk_output.block2.block2-0.f.a.0', 'trunk_output.block2.block2-0.f.a.1', 'trunk_output.block2.block2-0.f.a.2', 'trunk_output.block2.block2-0.f.b.0', 'trunk_output.block2.block2-0.f.b.1', 'trunk_output.block2.block2-0.f.b.2', 'trunk_output.block2.block2-0.f.c.0', 'trunk_output.block2.block2-0.f.c.1', 'trunk_output.block2.block2-0.add', 'trunk_output.block2.block2-0.activation', 'trunk_output.block2.block2-1.f.a.0', 'trunk_output.block2.block2-1.f.a.1', 'trunk_output.block2.block2-1.f.a.2', 'trunk_output.block2.block2-1.f.b.0', 'trunk_output.block2.block2-1.f.b.1', 'trunk_output.block2.block2-1.f.b.2', 'trunk_output.block2.block2-1.f.c.0', 'trunk_output.block2.block2-1.f.c.1', 'trunk_output.block2.block2-1.add', 'trunk_output.block2.block2-1.activation', 'trunk_output.block3.block3-0.proj.0', 'trunk_output.block3.block3-0.proj.1', 'trunk_output.block3.block3-0.f.a.0', 'trunk_output.block3.block3-0.f.a.1', 'trunk_output.block3.block3-0.f.a.2', 'trunk_output.block3.block3-0.f.b.0', 'trunk_output.block3.block3-0.f.b.1', 'trunk_output.block3.block3-0.f.b.2', 'trunk_output.block3.block3-0.f.c.0', 'trunk_output.block3.block3-0.f.c.1', 'trunk_output.block3.block3-0.add', 'trunk_output.block3.block3-0.activation', 'trunk_output.block3.block3-1.f.a.0', 'trunk_output.block3.block3-1.f.a.1', 'trunk_output.block3.block3-1.f.a.2', 'trunk_output.block3.block3-1.f.b.0', 'trunk_output.block3.block3-1.f.b.1', 'trunk_output.block3.block3-1.f.b.2', 'trunk_output.block3.block3-1.f.c.0', 'trunk_output.block3.block3-1.f.c.1', 'trunk_output.block3.block3-1.add', 'trunk_output.block3.block3-1.activation', 'trunk_output.block3.block3-2.f.a.0', 'trunk_output.block3.block3-2.f.a.1', 'trunk_output.block3.block3-2.f.a.2', 'trunk_output.block3.block3-2.f.b.0', 'trunk_output.block3.block3-2.f.b.1', 'trunk_output.block3.block3-2.f.b.2', 'trunk_output.block3.block3-2.f.c.0', 'trunk_output.block3.block3-2.f.c.1', 'trunk_output.block3.block3-2.add', 'trunk_output.block3.block3-2.activation', 'trunk_output.block3.block3-3.f.a.0', 'trunk_output.block3.block3-3.f.a.1', 'trunk_output.block3.block3-3.f.a.2', 'trunk_output.block3.block3-3.f.b.0', 'trunk_output.block3.block3-3.f.b.1', 'trunk_output.block3.block3-3.f.b.2', 'trunk_output.block3.block3-3.f.c.0', 'trunk_output.block3.block3-3.f.c.1', 'trunk_output.block3.block3-3.add', 'trunk_output.block3.block3-3.activation', 'trunk_output.block3.block3-4.f.a.0', 'trunk_output.block3.block3-4.f.a.1', 'trunk_output.block3.block3-4.f.a.2', 'trunk_output.block3.block3-4.f.b.0', 'trunk_output.block3.block3-4.f.b.1', 'trunk_output.block3.block3-4.f.b.2', 'trunk_output.block3.block3-4.f.c.0', 'trunk_output.block3.block3-4.f.c.1', 'trunk_output.block3.block3-4.add', 'trunk_output.block3.block3-4.activation', 'trunk_output.block3.block3-5.f.a.0', 'trunk_output.block3.block3-5.f.a.1', 'trunk_output.block3.block3-5.f.a.2', 'trunk_output.block3.block3-5.f.b.0', 'trunk_output.block3.block3-5.f.b.1', 'trunk_output.block3.block3-5.f.b.2', 'trunk_output.block3.block3-5.f.c.0', 'trunk_output.block3.block3-5.f.c.1', 'trunk_output.block3.block3-5.add', 'trunk_output.block3.block3-5.activation', 'trunk_output.block3.block3-6.f.a.0', 'trunk_output.block3.block3-6.f.a.1', 'trunk_output.block3.block3-6.f.a.2', 'trunk_output.block3.block3-6.f.b.0', 'trunk_output.block3.block3-6.f.b.1', 'trunk_output.block3.block3-6.f.b.2', 'trunk_output.block3.block3-6.f.c.0', 'trunk_output.block3.block3-6.f.c.1', 'trunk_output.block3.block3-6.add', 'trunk_output.block3.block3-6.activation', 'trunk_output.block4.block4-0.proj.0', 'trunk_output.block4.block4-0.proj.1', 'trunk_output.block4.block4-0.f.a.0', 'trunk_output.block4.block4-0.f.a.1', 'trunk_output.block4.block4-0.f.a.2', 'trunk_output.block4.block4-0.f.b.0', 'trunk_output.block4.block4-0.f.b.1', 'trunk_output.block4.block4-0.f.b.2', 'trunk_output.block4.block4-0.f.c.0', 'trunk_output.block4.block4-0.f.c.1', 'trunk_output.block4.block4-0.add', 'trunk_output.block4.block4-0.activation', 'trunk_output.block4.block4-1.f.a.0', 'trunk_output.block4.block4-1.f.a.1', 'trunk_output.block4.block4-1.f.a.2', 'trunk_output.block4.block4-1.f.b.0', 'trunk_output.block4.block4-1.f.b.1', 'trunk_output.block4.block4-1.f.b.2', 'trunk_output.block4.block4-1.f.c.0', 'trunk_output.block4.block4-1.f.c.1', 'trunk_output.block4.block4-1.add', 'trunk_output.block4.block4-1.activation', 'trunk_output.block4.block4-2.f.a.0', 'trunk_output.block4.block4-2.f.a.1', 'trunk_output.block4.block4-2.f.a.2', 'trunk_output.block4.block4-2.f.b.0', 'trunk_output.block4.block4-2.f.b.1', 'trunk_output.block4.block4-2.f.b.2', 'trunk_output.block4.block4-2.f.c.0', 'trunk_output.block4.block4-2.f.c.1', 'trunk_output.block4.block4-2.add', 'trunk_output.block4.block4-2.activation', 'trunk_output.block4.block4-3.f.a.0', 'trunk_output.block4.block4-3.f.a.1', 'trunk_output.block4.block4-3.f.a.2', 'trunk_output.block4.block4-3.f.b.0', 'trunk_output.block4.block4-3.f.b.1', 'trunk_output.block4.block4-3.f.b.2', 'trunk_output.block4.block4-3.f.c.0', 'trunk_output.block4.block4-3.f.c.1', 'trunk_output.block4.block4-3.add', 'trunk_output.block4.block4-3.activation', 'trunk_output.block4.block4-4.f.a.0', 'trunk_output.block4.block4-4.f.a.1', 'trunk_output.block4.block4-4.f.a.2', 'trunk_output.block4.block4-4.f.b.0', 'trunk_output.block4.block4-4.f.b.1', 'trunk_output.block4.block4-4.f.b.2', 'trunk_output.block4.block4-4.f.c.0', 'trunk_output.block4.block4-4.f.c.1', 'trunk_output.block4.block4-4.add', 'trunk_output.block4.block4-4.activation', 'trunk_output.block4.block4-5.f.a.0', 'trunk_output.block4.block4-5.f.a.1', 'trunk_output.block4.block4-5.f.a.2', 'trunk_output.block4.block4-5.f.b.0', 'trunk_output.block4.block4-5.f.b.1', 'trunk_output.block4.block4-5.f.b.2', 'trunk_output.block4.block4-5.f.c.0', 'trunk_output.block4.block4-5.f.c.1', 'trunk_output.block4.block4-5.add', 'trunk_output.block4.block4-5.activation', 'trunk_output.block4.block4-6.f.a.0', 'trunk_output.block4.block4-6.f.a.1', 'trunk_output.block4.block4-6.f.a.2', 'trunk_output.block4.block4-6.f.b.0', 'trunk_output.block4.block4-6.f.b.1', 'trunk_output.block4.block4-6.f.b.2', 'trunk_output.block4.block4-6.f.c.0', 'trunk_output.block4.block4-6.f.c.1', 'trunk_output.block4.block4-6.add', 'trunk_output.block4.block4-6.activation', 'trunk_output.block4.block4-7.f.a.0', 'trunk_output.block4.block4-7.f.a.1', 'trunk_output.block4.block4-7.f.a.2', 'trunk_output.block4.block4-7.f.b.0', 'trunk_output.block4.block4-7.f.b.1', 'trunk_output.block4.block4-7.f.b.2', 'trunk_output.block4.block4-7.f.c.0', 'trunk_output.block4.block4-7.f.c.1', 'trunk_output.block4.block4-7.add', 'trunk_output.block4.block4-7.activation', 'trunk_output.block4.block4-8.f.a.0', 'trunk_output.block4.block4-8.f.a.1', 'trunk_output.block4.block4-8.f.a.2', 'trunk_output.block4.block4-8.f.b.0', 'trunk_output.block4.block4-8.f.b.1', 'trunk_output.block4.block4-8.f.b.2', 'trunk_output.block4.block4-8.f.c.0', 'trunk_output.block4.block4-8.f.c.1', 'trunk_output.block4.block4-8.add', 'trunk_output.block4.block4-8.activation', 'trunk_output.block4.block4-9.f.a.0', 'trunk_output.block4.block4-9.f.a.1', 'trunk_output.block4.block4-9.f.a.2', 'trunk_output.block4.block4-9.f.b.0', 'trunk_output.block4.block4-9.f.b.1', 'trunk_output.block4.block4-9.f.b.2', 'trunk_output.block4.block4-9.f.c.0', 'trunk_output.block4.block4-9.f.c.1', 'trunk_output.block4.block4-9.add', 'trunk_output.block4.block4-9.activation', 'trunk_output.block4.block4-10.f.a.0', 'trunk_output.block4.block4-10.f.a.1', 'trunk_output.block4.block4-10.f.a.2', 'trunk_output.block4.block4-10.f.b.0', 'trunk_output.block4.block4-10.f.b.1', 'trunk_output.block4.block4-10.f.b.2', 'trunk_output.block4.block4-10.f.c.0', 'trunk_output.block4.block4-10.f.c.1', 'trunk_output.block4.block4-10.add', 'trunk_output.block4.block4-10.activation', 'trunk_output.block4.block4-11.f.a.0', 'trunk_output.block4.block4-11.f.a.1', 'trunk_output.block4.block4-11.f.a.2', 'trunk_output.block4.block4-11.f.b.0', 'trunk_output.block4.block4-11.f.b.1', 'trunk_output.block4.block4-11.f.b.2', 'trunk_output.block4.block4-11.f.c.0', 'trunk_output.block4.block4-11.f.c.1', 'trunk_output.block4.block4-11.add', 'trunk_output.block4.block4-11.activation', 'avgpool', 'flatten', 'fc']\n",
      "['x', 'stem.0', 'stem.1', 'stem.2', 'trunk_output.block1.block1-0.proj.0', 'trunk_output.block1.block1-0.proj.1', 'trunk_output.block1.block1-0.f.a.0', 'trunk_output.block1.block1-0.f.a.1', 'trunk_output.block1.block1-0.f.a.2', 'trunk_output.block1.block1-0.f.b.0', 'trunk_output.block1.block1-0.f.b.1', 'trunk_output.block1.block1-0.f.b.2', 'trunk_output.block1.block1-0.f.c.0', 'trunk_output.block1.block1-0.f.c.1', 'trunk_output.block1.block1-0.add', 'trunk_output.block1.block1-0.activation', 'trunk_output.block2.block2-0.proj.0', 'trunk_output.block2.block2-0.proj.1', 'trunk_output.block2.block2-0.f.a.0', 'trunk_output.block2.block2-0.f.a.1', 'trunk_output.block2.block2-0.f.a.2', 'trunk_output.block2.block2-0.f.b.0', 'trunk_output.block2.block2-0.f.b.1', 'trunk_output.block2.block2-0.f.b.2', 'trunk_output.block2.block2-0.f.c.0', 'trunk_output.block2.block2-0.f.c.1', 'trunk_output.block2.block2-0.add', 'trunk_output.block2.block2-0.activation', 'trunk_output.block2.block2-1.f.a.0', 'trunk_output.block2.block2-1.f.a.1', 'trunk_output.block2.block2-1.f.a.2', 'trunk_output.block2.block2-1.f.b.0', 'trunk_output.block2.block2-1.f.b.1', 'trunk_output.block2.block2-1.f.b.2', 'trunk_output.block2.block2-1.f.c.0', 'trunk_output.block2.block2-1.f.c.1', 'trunk_output.block2.block2-1.add', 'trunk_output.block2.block2-1.activation', 'trunk_output.block3.block3-0.proj.0', 'trunk_output.block3.block3-0.proj.1', 'trunk_output.block3.block3-0.f.a.0', 'trunk_output.block3.block3-0.f.a.1', 'trunk_output.block3.block3-0.f.a.2', 'trunk_output.block3.block3-0.f.b.0', 'trunk_output.block3.block3-0.f.b.1', 'trunk_output.block3.block3-0.f.b.2', 'trunk_output.block3.block3-0.f.c.0', 'trunk_output.block3.block3-0.f.c.1', 'trunk_output.block3.block3-0.add', 'trunk_output.block3.block3-0.activation', 'trunk_output.block3.block3-1.f.a.0', 'trunk_output.block3.block3-1.f.a.1', 'trunk_output.block3.block3-1.f.a.2', 'trunk_output.block3.block3-1.f.b.0', 'trunk_output.block3.block3-1.f.b.1', 'trunk_output.block3.block3-1.f.b.2', 'trunk_output.block3.block3-1.f.c.0', 'trunk_output.block3.block3-1.f.c.1', 'trunk_output.block3.block3-1.add', 'trunk_output.block3.block3-1.activation', 'trunk_output.block3.block3-2.f.a.0', 'trunk_output.block3.block3-2.f.a.1', 'trunk_output.block3.block3-2.f.a.2', 'trunk_output.block3.block3-2.f.b.0', 'trunk_output.block3.block3-2.f.b.1', 'trunk_output.block3.block3-2.f.b.2', 'trunk_output.block3.block3-2.f.c.0', 'trunk_output.block3.block3-2.f.c.1', 'trunk_output.block3.block3-2.add', 'trunk_output.block3.block3-2.activation', 'trunk_output.block3.block3-3.f.a.0', 'trunk_output.block3.block3-3.f.a.1', 'trunk_output.block3.block3-3.f.a.2', 'trunk_output.block3.block3-3.f.b.0', 'trunk_output.block3.block3-3.f.b.1', 'trunk_output.block3.block3-3.f.b.2', 'trunk_output.block3.block3-3.f.c.0', 'trunk_output.block3.block3-3.f.c.1', 'trunk_output.block3.block3-3.add', 'trunk_output.block3.block3-3.activation', 'trunk_output.block3.block3-4.f.a.0', 'trunk_output.block3.block3-4.f.a.1', 'trunk_output.block3.block3-4.f.a.2', 'trunk_output.block3.block3-4.f.b.0', 'trunk_output.block3.block3-4.f.b.1', 'trunk_output.block3.block3-4.f.b.2', 'trunk_output.block3.block3-4.f.c.0', 'trunk_output.block3.block3-4.f.c.1', 'trunk_output.block3.block3-4.add', 'trunk_output.block3.block3-4.activation', 'trunk_output.block3.block3-5.f.a.0', 'trunk_output.block3.block3-5.f.a.1', 'trunk_output.block3.block3-5.f.a.2', 'trunk_output.block3.block3-5.f.b.0', 'trunk_output.block3.block3-5.f.b.1', 'trunk_output.block3.block3-5.f.b.2', 'trunk_output.block3.block3-5.f.c.0', 'trunk_output.block3.block3-5.f.c.1', 'trunk_output.block3.block3-5.add', 'trunk_output.block3.block3-5.activation', 'trunk_output.block3.block3-6.f.a.0', 'trunk_output.block3.block3-6.f.a.1', 'trunk_output.block3.block3-6.f.a.2', 'trunk_output.block3.block3-6.f.b.0', 'trunk_output.block3.block3-6.f.b.1', 'trunk_output.block3.block3-6.f.b.2', 'trunk_output.block3.block3-6.f.c.0', 'trunk_output.block3.block3-6.f.c.1', 'trunk_output.block3.block3-6.add', 'trunk_output.block3.block3-6.activation', 'trunk_output.block4.block4-0.proj.0', 'trunk_output.block4.block4-0.proj.1', 'trunk_output.block4.block4-0.f.a.0', 'trunk_output.block4.block4-0.f.a.1', 'trunk_output.block4.block4-0.f.a.2', 'trunk_output.block4.block4-0.f.b.0', 'trunk_output.block4.block4-0.f.b.1', 'trunk_output.block4.block4-0.f.b.2', 'trunk_output.block4.block4-0.f.c.0', 'trunk_output.block4.block4-0.f.c.1', 'trunk_output.block4.block4-0.add', 'trunk_output.block4.block4-0.activation', 'trunk_output.block4.block4-1.f.a.0', 'trunk_output.block4.block4-1.f.a.1', 'trunk_output.block4.block4-1.f.a.2', 'trunk_output.block4.block4-1.f.b.0', 'trunk_output.block4.block4-1.f.b.1', 'trunk_output.block4.block4-1.f.b.2', 'trunk_output.block4.block4-1.f.c.0', 'trunk_output.block4.block4-1.f.c.1', 'trunk_output.block4.block4-1.add', 'trunk_output.block4.block4-1.activation', 'trunk_output.block4.block4-2.f.a.0', 'trunk_output.block4.block4-2.f.a.1', 'trunk_output.block4.block4-2.f.a.2', 'trunk_output.block4.block4-2.f.b.0', 'trunk_output.block4.block4-2.f.b.1', 'trunk_output.block4.block4-2.f.b.2', 'trunk_output.block4.block4-2.f.c.0', 'trunk_output.block4.block4-2.f.c.1', 'trunk_output.block4.block4-2.add', 'trunk_output.block4.block4-2.activation', 'trunk_output.block4.block4-3.f.a.0', 'trunk_output.block4.block4-3.f.a.1', 'trunk_output.block4.block4-3.f.a.2', 'trunk_output.block4.block4-3.f.b.0', 'trunk_output.block4.block4-3.f.b.1', 'trunk_output.block4.block4-3.f.b.2', 'trunk_output.block4.block4-3.f.c.0', 'trunk_output.block4.block4-3.f.c.1', 'trunk_output.block4.block4-3.add', 'trunk_output.block4.block4-3.activation', 'trunk_output.block4.block4-4.f.a.0', 'trunk_output.block4.block4-4.f.a.1', 'trunk_output.block4.block4-4.f.a.2', 'trunk_output.block4.block4-4.f.b.0', 'trunk_output.block4.block4-4.f.b.1', 'trunk_output.block4.block4-4.f.b.2', 'trunk_output.block4.block4-4.f.c.0', 'trunk_output.block4.block4-4.f.c.1', 'trunk_output.block4.block4-4.add', 'trunk_output.block4.block4-4.activation', 'trunk_output.block4.block4-5.f.a.0', 'trunk_output.block4.block4-5.f.a.1', 'trunk_output.block4.block4-5.f.a.2', 'trunk_output.block4.block4-5.f.b.0', 'trunk_output.block4.block4-5.f.b.1', 'trunk_output.block4.block4-5.f.b.2', 'trunk_output.block4.block4-5.f.c.0', 'trunk_output.block4.block4-5.f.c.1', 'trunk_output.block4.block4-5.add', 'trunk_output.block4.block4-5.activation', 'trunk_output.block4.block4-6.f.a.0', 'trunk_output.block4.block4-6.f.a.1', 'trunk_output.block4.block4-6.f.a.2', 'trunk_output.block4.block4-6.f.b.0', 'trunk_output.block4.block4-6.f.b.1', 'trunk_output.block4.block4-6.f.b.2', 'trunk_output.block4.block4-6.f.c.0', 'trunk_output.block4.block4-6.f.c.1', 'trunk_output.block4.block4-6.add', 'trunk_output.block4.block4-6.activation', 'trunk_output.block4.block4-7.f.a.0', 'trunk_output.block4.block4-7.f.a.1', 'trunk_output.block4.block4-7.f.a.2', 'trunk_output.block4.block4-7.f.b.0', 'trunk_output.block4.block4-7.f.b.1', 'trunk_output.block4.block4-7.f.b.2', 'trunk_output.block4.block4-7.f.c.0', 'trunk_output.block4.block4-7.f.c.1', 'trunk_output.block4.block4-7.add', 'trunk_output.block4.block4-7.activation', 'trunk_output.block4.block4-8.f.a.0', 'trunk_output.block4.block4-8.f.a.1', 'trunk_output.block4.block4-8.f.a.2', 'trunk_output.block4.block4-8.f.b.0', 'trunk_output.block4.block4-8.f.b.1', 'trunk_output.block4.block4-8.f.b.2', 'trunk_output.block4.block4-8.f.c.0', 'trunk_output.block4.block4-8.f.c.1', 'trunk_output.block4.block4-8.add', 'trunk_output.block4.block4-8.activation', 'trunk_output.block4.block4-9.f.a.0', 'trunk_output.block4.block4-9.f.a.1', 'trunk_output.block4.block4-9.f.a.2', 'trunk_output.block4.block4-9.f.b.0', 'trunk_output.block4.block4-9.f.b.1', 'trunk_output.block4.block4-9.f.b.2', 'trunk_output.block4.block4-9.f.c.0', 'trunk_output.block4.block4-9.f.c.1', 'trunk_output.block4.block4-9.add', 'trunk_output.block4.block4-9.activation', 'trunk_output.block4.block4-10.f.a.0', 'trunk_output.block4.block4-10.f.a.1', 'trunk_output.block4.block4-10.f.a.2', 'trunk_output.block4.block4-10.f.b.0', 'trunk_output.block4.block4-10.f.b.1', 'trunk_output.block4.block4-10.f.b.2', 'trunk_output.block4.block4-10.f.c.0', 'trunk_output.block4.block4-10.f.c.1', 'trunk_output.block4.block4-10.add', 'trunk_output.block4.block4-10.activation', 'trunk_output.block4.block4-11.f.a.0', 'trunk_output.block4.block4-11.f.a.1', 'trunk_output.block4.block4-11.f.a.2', 'trunk_output.block4.block4-11.f.b.0', 'trunk_output.block4.block4-11.f.b.1', 'trunk_output.block4.block4-11.f.b.2', 'trunk_output.block4.block4-11.f.c.0', 'trunk_output.block4.block4-11.f.c.1', 'trunk_output.block4.block4-11.add', 'trunk_output.block4.block4-11.activation', 'avgpool', 'flatten', 'fc']\n"
     ]
    }
   ],
   "source": [
    "# model block sanity check\n",
    "model = torchvision.models.regnet_x_400mf(pretrained=True)\n",
    "train_nodes, eval_nodes = torchvision.models.feature_extraction.get_graph_node_names(model)\n",
    "\n",
    "print(train_nodes)\n",
    "print(eval_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPN trainability check\n",
    "\n",
    "# from torch import nn\n",
    "# from a4_helper import train_detector\n",
    "# from common import DetectorBackboneWithFPN\n",
    "# from FPN_ROI import RPN\n",
    "# reset_seed(0)\n",
    "\n",
    "# # Take equally spaced examples from training dataset to make a subset.\n",
    "# small_dataset = torch.utils.data.Subset(\n",
    "#     train_dataset,\n",
    "#     torch.linspace(0, len(train_dataset) - 1, steps=BATCH_SIZE * 10).long()\n",
    "# )\n",
    "# small_train_loader = torch.utils.data.DataLoader(\n",
    "#     small_dataset, batch_size=BATCH_SIZE, pin_memory=True\n",
    "# )\n",
    "\n",
    "# # Create a wrapper module to contain backbone + RPN:\n",
    "# class FirstStage(nn.Module):\n",
    "#     def __init__(self, fpn_channels: int):\n",
    "#         super().__init__()\n",
    "#         self.backbone = DetectorBackboneWithFPN(out_channels=fpn_channels)\n",
    "#         self.rpn = RPN(\n",
    "#             fpn_channels=fpn_channels,\n",
    "#             # Simple stem of two layers:\n",
    "#             stem_channels=[fpn_channels, fpn_channels],\n",
    "#             batch_size_per_image=16,\n",
    "#             anchor_stride_scale=8,\n",
    "#             anchor_aspect_ratios=[0.5, 1.0, 2.0],\n",
    "#             anchor_iou_thresholds=(0.3, 0.6),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, images, gt_boxes=None):\n",
    "#         feats_per_fpn_level = self.backbone(images)\n",
    "#         return self.rpn(feats_per_fpn_level, self.backbone.fpn_strides, gt_boxes)\n",
    "\n",
    "\n",
    "# first_stage = FirstStage(fpn_channels=64).to(DEVICE)\n",
    "\n",
    "# train_detector(\n",
    "#     first_stage,\n",
    "#     small_train_loader,\n",
    "#     learning_rate=8e-3,\n",
    "#     max_iters=1000,\n",
    "#     log_period=20,\n",
    "#     device=DEVICE,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image batch has shape : torch.Size([16, 3, 896, 896])\n",
      "gt_boxes has shape    : torch.Size([16, 40, 5])\n",
      "Five boxes per image  :\n",
      "tensor([[[195.7477, 260.9970, 720.4324, 726.4865,   6.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[313.3846, 152.6154, 544.7692, 489.8461,  14.0000],\n",
      "         [ 79.5385, 192.0000, 850.0000, 827.0769,  12.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[ 24.1437, 395.0060, 657.2455, 896.0000,   1.0000],\n",
      "         [617.0060, 368.1796, 896.0000, 896.0000,   1.0000],\n",
      "         [  5.3653,   0.0000, 313.8683, 767.8922,  14.0000],\n",
      "         [  8.0479,   0.0000, 651.8802, 896.0000,  14.0000],\n",
      "         [603.5928,   0.0000, 896.0000, 896.0000,  14.0000]],\n",
      "\n",
      "        [[ 18.1622, 336.3364, 682.7628, 570.4264,   6.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[  0.0000, 248.7118, 846.7295, 583.5160,   0.0000],\n",
      "         [ 75.0854, 280.5979, 279.1566, 392.1993,   0.0000],\n",
      "         [272.7794, 573.9502, 330.1744, 730.1921,  14.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[  0.0000, 261.9453, 896.0000, 643.8470,   0.0000],\n",
      "         [866.6448, 489.6175, 896.0000, 553.2678,   0.0000],\n",
      "         [631.6284, 460.2404, 842.1639, 545.9235,   0.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[288.7111, 241.6444, 896.0000, 821.5556,  18.0000],\n",
      "         [350.9333, 206.8000, 828.8000, 395.9556,  18.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[  0.0000, 229.3760, 307.3626, 862.5494,  14.0000],\n",
      "         [371.8746, 234.1547, 896.0000, 759.8080,  14.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[ 72.8675,   0.0000, 860.9156, 702.3856,  11.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[483.4269,  85.5881, 896.0000, 789.0149,  18.0000],\n",
      "         [  0.0000,  96.2866, 408.5374, 799.7134,  18.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[  0.0000,   2.6907, 771.5555, 887.9279,   8.0000],\n",
      "         [ 42.3784, 271.7598, 615.4955, 573.1171,   7.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[  0.0000,   2.6907, 896.0000, 839.4955,   6.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[138.5813, 106.6587, 695.2960, 896.0000,   2.0000],\n",
      "         [  4.7787,   0.0000, 721.5787, 896.0000,  14.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[513.2492,  29.5976, 896.0000, 750.7027,   3.0000],\n",
      "         [271.0871, 575.8078, 532.0840, 678.0541,   3.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[  1.8065,  38.5484, 814.7097, 896.0000,   2.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
      "\n",
      "        [[350.3707, 446.8053, 395.7680, 549.5467,  14.0000],\n",
      "         [429.2186, 434.8586, 505.6773, 618.8373,  14.0000],\n",
      "         [493.7307, 449.1947, 555.8533, 618.8373,  14.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
      "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000,  -1.0000]]])\n",
      "tensor([[-0.8678, -0.8849, -0.9020,  ..., -0.9705, -0.9705, -0.9877],\n",
      "        [-0.8678, -0.8849, -0.9020,  ..., -0.9705, -0.9705, -0.9877],\n",
      "        [-0.8678, -0.8849, -0.9020,  ..., -0.9534, -0.9534, -0.9705],\n",
      "        ...,\n",
      "        [-0.6794, -0.6623, -0.6794,  ..., -0.9705, -1.0048, -1.0390],\n",
      "        [-0.7137, -0.6965, -0.6965,  ..., -0.9877, -1.0048, -1.0390],\n",
      "        [-0.7137, -0.6965, -0.6965,  ..., -0.9877, -1.0048, -1.0390]])\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=1, pin_memory=True\n",
    ")\n",
    "\n",
    "train_loader_iter = iter(train_loader)\n",
    "image_paths, images, gt_boxes = train_loader_iter.next()\n",
    "\n",
    "# print(f\"image paths           : {image_paths}\")\n",
    "print(f\"image batch has shape : {images.shape}\")\n",
    "print(f\"gt_boxes has shape    : {gt_boxes.shape}\")\n",
    "\n",
    "print(f\"Five boxes per image  :\")\n",
    "print(gt_boxes[:, :5, :])\n",
    "print(images[0,0,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dummy input images with shape: (2, 3, 224, 224)\n",
      "Shape of p3 features: torch.Size([16, 128, 112, 112])\n",
      "Shape of p4 features: torch.Size([16, 128, 56, 56])\n",
      "Shape of p5 features: torch.Size([16, 128, 28, 28])\n",
      "Shape of p6 features: torch.Size([16, 128, 14, 14])\n",
      "Shape of p7 features: torch.Size([16, 128, 7, 7])\n",
      "dict_keys(['p3', 'p4', 'p5', 'p6', 'p7'])\n",
      "torch.Size([33, 3, 896, 896])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"unfolded2d_copy\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12448/611696225.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mlog_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wuxin\\OneDrive\\桌面\\EECS545\\project\\program\\a4_helper.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[1;34m(detector, train_loader, learning_rate, weight_decay, max_iters, log_period, device)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;31m# Dictionary of loss scalars.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;31m# Ignore keys like \"proposals\" in RPN.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wuxin\\OneDrive\\桌面\\EECS545\\project\\program\\FPN_ROI.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, gt_boxes, test_score_thresh, test_nms_thresh)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m             \u001b[0mimage_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclipmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped_images_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\clip\\model.py\u001b[0m in \u001b[0;36mencode_image\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\clip\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# shape = [*, width, grid, grid]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# shape = [*, width, grid ** 2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# shape = [*, grid ** 2, width]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 443\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"unfolded2d_copy\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "from a4_helper import train_detector\n",
    "from common import DetectorBackboneWithFPN\n",
    "from FPN_ROI import RPN\n",
    "\n",
    "reset_seed(0)\n",
    "from FPN_ROI import FasterRCNN\n",
    "\n",
    "# Slightly larger detector than in above cell.\n",
    "FPN_CHANNELS = 128\n",
    "backbone = DetectorBackboneWithFPN(out_channels=FPN_CHANNELS)\n",
    "rpn = RPN(\n",
    "    fpn_channels=FPN_CHANNELS,\n",
    "    stem_channels=[FPN_CHANNELS, FPN_CHANNELS],\n",
    "    batch_size_per_image=16,\n",
    "    pre_nms_topk=500,\n",
    "    post_nms_topk=200  # Other args from previous cell are default args in RPN.\n",
    ")\n",
    "# fmt: off\n",
    "faster_rcnn = FasterRCNN(\n",
    "    backbone, rpn, num_classes=NUM_CLASSES, roi_size=(7, 7),\n",
    "    stem_channels=[FPN_CHANNELS, FPN_CHANNELS],\n",
    "    batch_size_per_image=32,\n",
    ")\n",
    "# fmt: on\n",
    "\n",
    "train_detector(\n",
    "    faster_rcnn,\n",
    "    train_loader,\n",
    "    learning_rate=0.01,\n",
    "    max_iters=9000,\n",
    "    log_period=50,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# After you've trained your model, save the weights for submission.\n",
    "weights_path = os.path.join('./A4', \"rcnn_detector.pt\")\n",
    "torch.save(faster_rcnn.state_dict(), weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clip\n",
    "\n",
    "clip.available_models()\n",
    "model, preprocess = clip.load(\"ViT-B/32\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f18262e1a2788be3d4c180962476641642a277e294ea61ec51e87943ad89b761"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
